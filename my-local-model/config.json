{
  "architectures": [
    "RobertaForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "E10",
    "1": "E11",
    "2": "E12",
    "3": "E13",
    "4": "E14",
    "5": "E15",
    "6": "E16",
    "7": "E17",
    "8": "E18",
    "9": "E19",
    "10": "E20",
    "11": "E21",
    "12": "E22",
    "13": "E23",
    "14": "E24",
    "15": "E25",
    "16": "E26",
    "17": "E27",
    "18": "E28",
    "19": "E29",
    "20": "E30",
    "21": "E31",
    "22": "E32",
    "23": "E33",
    "24": "E34",
    "25": "E35",
    "26": "E36",
    "27": "E37",
    "28": "E38",
    "29": "E39",
    "30": "E40",
    "31": "E41",
    "32": "E42",
    "33": "E43",
    "34": "E44",
    "35": "E45",
    "36": "E46",
    "37": "E47",
    "38": "E48",
    "39": "E49",
    "40": "E50",
    "41": "E51",
    "42": "E52",
    "43": "E53",
    "44": "E54",
    "45": "E55",
    "46": "E56",
    "47": "E57",
    "48": "E58",
    "49": "E59",
    "50": "E60",
    "51": "E61",
    "52": "E62",
    "53": "E63",
    "54": "E64",
    "55": "E65",
    "56": "E66",
    "57": "E67",
    "58": "E68",
    "59": "E69"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "E10": 0,
    "E11": 1,
    "E12": 2,
    "E13": 3,
    "E14": 4,
    "E15": 5,
    "E16": 6,
    "E17": 7,
    "E18": 8,
    "E19": 9,
    "E20": 10,
    "E21": 11,
    "E22": 12,
    "E23": 13,
    "E24": 14,
    "E25": 15,
    "E26": 16,
    "E27": 17,
    "E28": 18,
    "E29": 19,
    "E30": 20,
    "E31": 21,
    "E32": 22,
    "E33": 23,
    "E34": 24,
    "E35": 25,
    "E36": 26,
    "E37": 27,
    "E38": 28,
    "E39": 29,
    "E40": 30,
    "E41": 31,
    "E42": 32,
    "E43": 33,
    "E44": 34,
    "E45": 35,
    "E46": 36,
    "E47": 37,
    "E48": 38,
    "E49": 39,
    "E50": 40,
    "E51": 41,
    "E52": 42,
    "E53": 43,
    "E54": 44,
    "E55": 45,
    "E56": 46,
    "E57": 47,
    "E58": 48,
    "E59": 49,
    "E60": 50,
    "E61": 51,
    "E62": 52,
    "E63": 53,
    "E64": 54,
    "E65": 55,
    "E66": 56,
    "E67": 57,
    "E68": 58,
    "E69": 59
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "problem_type": "single_label_classification",
  "tokenizer_class": "BertTokenizer",
  "torch_dtype": "float32",
  "transformers_version": "4.55.2",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 32000
}
